{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d310e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de31e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec092cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "cutoff = pd.Timestamp(\"2016-05-20 17:00:00\")\n",
    "df_clean = df.loc[df[\"timestamp\"] >= cutoff].copy()\n",
    "df_clean = df_clean.query(\"building_id != 53\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7543687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 698675 entries, 0 to 698674\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   building_id         698675 non-null  int64         \n",
      " 1   timestamp           698675 non-null  datetime64[ns]\n",
      " 2   meter_reading       698675 non-null  float64       \n",
      " 3   primary_use         698675 non-null  object        \n",
      " 4   square_feet         698675 non-null  int64         \n",
      " 5   year_built          698675 non-null  int64         \n",
      " 6   air_temperature     698452 non-null  float64       \n",
      " 7   cloud_coverage      394159 non-null  float64       \n",
      " 8   dew_temperature     698452 non-null  float64       \n",
      " 9   precip_depth_1_hr   698591 non-null  float64       \n",
      " 10  sea_level_pressure  691953 non-null  float64       \n",
      " 11  wind_direction      678753 non-null  float64       \n",
      " 12  wind_speed          698675 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(3), object(1)\n",
      "memory usage: 69.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0f504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2d954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                0\n",
       "timestamp                  0\n",
       "meter_reading              0\n",
       "primary_use                0\n",
       "square_feet                0\n",
       "year_built                 0\n",
       "air_temperature            0\n",
       "cloud_coverage        180152\n",
       "dew_temperature            0\n",
       "precip_depth_1_hr          0\n",
       "sea_level_pressure      2191\n",
       "wind_direction         13924\n",
       "wind_speed                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750128dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df_clean.timestamp <  \"2016-11-01\"\n",
    "val_mask   = (df_clean.timestamp >= \"2016-11-01\") & (df_clean.timestamp < \"2016-12-01\")\n",
    "test_mask  = df_clean.timestamp >=  \"2016-12-01\"\n",
    "\n",
    "df_clean[\"y_log\"] = np.log1p(df_clean[\"meter_reading\"])\n",
    "\n",
    "num_cols = df_clean.columns.difference(\n",
    "    [\"building_id\", \"primary_use\", \"meter_reading\", \"y_log\", \"timestamp\"]\n",
    ")\n",
    "cat_cols_onehot = [\"primary_use\"]   # one‑hot\n",
    "cat_cols_lgbm   = [\"building_id\"]   # leave as category\n",
    "\n",
    "X_raw = df_clean[num_cols.tolist() + cat_cols_onehot + cat_cols_lgbm].copy()\n",
    "X_raw[\"building_id\"] = X_raw[\"building_id\"].astype(\"category\")\n",
    "\n",
    "y_raw = df_clean[\"y_log\"].values\n",
    "\n",
    "X_train_raw, y_train = X_raw[train_mask], y_raw[train_mask]\n",
    "X_val_raw,   y_val   = X_raw[val_mask],   y_raw[val_mask]\n",
    "X_test_raw,  y_test  = X_raw[test_mask],  y_raw[test_mask]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_onehot)],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "X_train = pre.fit_transform(X_train_raw)\n",
    "X_val   = pre.transform(X_val_raw)\n",
    "X_test  = pre.transform(X_test_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f027bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline LightGBM …\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 651\n",
      "[LightGBM] [Info] Number of data points in the train set: 313826, number of used features: 17\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Start training from score 1.664781\n",
      "[200]\tvalid_0's rmse: 0.470619\n",
      "[400]\tvalid_0's rmse: 0.479531\n",
      "[600]\tvalid_0's rmse: 0.485499\n",
      "[800]\tvalid_0's rmse: 0.491106\n",
      "[1000]\tvalid_0's rmse: 0.49542\n",
      "[1200]\tvalid_0's rmse: 0.499635\n",
      "[1400]\tvalid_0's rmse: 0.505517\n",
      "[1600]\tvalid_0's rmse: 0.508488\n",
      "[1800]\tvalid_0's rmse: 0.511592\n",
      "[2000]\tvalid_0's rmse: 0.514782\n",
      "\n",
      "Best iteration              : 118\n",
      "Validation RMSE (log-space) : 0.46441\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "Test RMSE (kWh)             : 145.52\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.LGBMRegressor(\n",
    "    objective          = \"tweedie\",\n",
    "    tweedie_variance_power = 1.1,     # 1.0 ≈ Poisson, 2.0 ≈ Gamma – 1.1 works well for energy\n",
    "    n_estimators       = 10000,      \n",
    "    learning_rate      = 0.03,\n",
    "    num_leaves         = 512,\n",
    "    feature_fraction   = 0.85,\n",
    "    bagging_fraction   = 0.85,\n",
    "    bagging_freq       = 5,\n",
    "    min_data_in_leaf   = 50,\n",
    "    random_state       = 42,\n",
    "    metric             = \"rmse\",     \n",
    ")\n",
    "\n",
    "print(\"Training baseline LightGBM …\")\n",
    "lgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=2000, verbose=False),\n",
    "        log_evaluation(period=200),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration              : {lgbm.best_iteration_}\")\n",
    "print(f\"Validation RMSE (log-space) : {lgbm.best_score_['valid_0']['rmse']:.5f}\")\n",
    "\n",
    "y_hat_test_log = lgbm.predict(X_test, num_iteration=lgbm.best_iteration_)\n",
    "# rmse_kwh = np.sqrt(((np.expm1(y_hat_test_log) - np.expm1(y_test))**2).mean())\n",
    "rmse_kwh = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_hat_test_log)))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Test RMSE (kWh)             : {rmse_kwh:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a87be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline XGBoost …\n",
      "[0]\tval-rmse:1.31369\n",
      "[200]\tval-rmse:0.46024\n",
      "[281]\tval-rmse:0.46513\n",
      "\n",
      "Best iteration              : 82\n",
      "Validation RMSE (log‑space) : 0.44373\n",
      "Test RMSE (kWh)             : 152.17\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val)\n",
    "dtest  = xgb.DMatrix(X_test,  label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,\n",
    "    \"seed\": 42,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "print(\"Training baseline XGBoost …\")\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=5000,\n",
    "    evals=[(dval, \"val\")],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200,\n",
    ")\n",
    "\n",
    "best_iter = bst.best_iteration\n",
    "val_rmse_log = bst.best_score\n",
    "print(f\"\\nBest iteration              : {best_iter}\")\n",
    "print(f\"Validation RMSE (log‑space) : {val_rmse_log:.5f}\")\n",
    "\n",
    "y_hat_test_log = bst.predict(dtest)\n",
    "rmse_kwh = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_hat_test_log)))\n",
    "\n",
    "print(f\"Test RMSE (kWh)             : {rmse_kwh:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33b0874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.47295\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46900\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.47828\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.47552\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45325\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46008\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45302\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46014\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45763\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45812\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45914\n",
      "params {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46624\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45581\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45601\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45323\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45709\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45856\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46078\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45430\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45823\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.48684\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.48877\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.47127\n",
      "params {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.48344\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.46589\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46259\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.46758\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46684\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45210\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45749\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45289\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45798\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.46897\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46788\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.47078\n",
      "params {'n_estimators': 600, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.47785\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45314\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45320\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45051\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45095\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.46993\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.47780\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.46565\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.47151\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.50374\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.50914\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.48575\n",
      "params {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.50174\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45387\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45416\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45923\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45787\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45559\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45843\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45209\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.46229\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.48348\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.48423\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.48542\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.03, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.49049\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45639\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45935\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.45252\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.45473\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.49231\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.49431\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.48624\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.48489\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.51810\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.8, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.52145\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.8}  -> val_RMSE_log 0.49980\n",
      "params {'n_estimators': 1200, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 1.0}  -> val_RMSE_log 0.51474\n",
      "\n",
      "Best log-space RMSE on Validation Set : 0.45051\n",
      "Best params : {'n_estimators': 600, 'learning_rate': 0.1, 'max_depth': 4, 'subsample': 1.0, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\":     [300, 600, 1200],\n",
    "    \"learning_rate\":    [0.03, 0.1],\n",
    "    \"max_depth\":        [4, 6, 8],\n",
    "    \"subsample\":        [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "}\n",
    "keys, values = zip(*grid.items())\n",
    "param_sets = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "best_params, best_rmse = None, float(\"inf\")\n",
    "\n",
    "for params in param_sets:\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = rmse(y_val, val_pred)        # log‑space RMSE\n",
    "\n",
    "    print(\"params\", params, \" -> val_RMSE_log {:.5f}\".format(val_rmse))\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest log-space RMSE on Validation Set :\", \"%.5f\" % best_rmse)\n",
    "print(\"Best params :\", best_params)\n",
    "\n",
    "X_trainval = np.vstack([X_train, X_val])\n",
    "y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    **best_params\n",
    ")\n",
    "final_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "test_pred_log = final_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20691ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE (kWh): 128.66\n"
     ]
    }
   ],
   "source": [
    "test_rmse_kwh = rmse(np.expm1(y_test), np.expm1(test_pred_log))\n",
    "print(\"test RMSE (kWh): {:.2f}\".format(test_rmse_kwh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460517f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
